{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/ssd/code/FaceID-model\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "isLocalServer = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import json, sys, os\n",
    "\n",
    "if isLocalServer is True:\n",
    "  print(f'This is in the local server, therefore your folder path should be added to the system path.')\n",
    "  \n",
    "  sys_path_to_be_added = '/notebook/personal/ksuchoi216/FaceID-model/'\n",
    "  if not sys_path_to_be_added in sys.path:\n",
    "    sys.path.insert(0, sys_path_to_be_added)\n",
    "    os.chdir(sys_path_to_be_added)\n",
    "\n",
    "  print(f'System path as follows:')\n",
    "  for path in sys.path:\n",
    "    print(f'    {path}')\n",
    "\n",
    "from utils import load_config\n",
    "cfg = load_config('config_test-various-face-extraction.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# loading numpy data\n",
    "\n",
    "def loadNumpyImagesToDict(user_names_list, data_source_path):\n",
    "  user_names = user_names_list\n",
    "  data_source = data_source_path\n",
    "\n",
    "  numpy_data = {}\n",
    "  print(numpy_data)\n",
    "  for i, user_name in enumerate(user_names):\n",
    "    print(i, user_name)\n",
    "    file_path = data_source + user_name + '_images.npy'\n",
    "    numpy_data[user_name] = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "  print('example dimension: {}'.format(numpy_data['jhyoo'].shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jhyoo', 'jhoh', 'jhongyoo', 'kschoi']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Confirm that opencv is installed on your environment! Expected path ', '/Users/KC/opt/anaconda3/envs/torch-cpu/lib/python3.8/site-packages/data/haarcascade_frontalface_default.xml', ' violated.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/ssd/code/FaceID-model/test_various-face-extraction.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/ssd/code/FaceID-model/test_various-face-extraction.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m img_path \u001b[39m=\u001b[39m data_source \u001b[39m+\u001b[39m user_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(num) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/ssd/code/FaceID-model/test_various-face-extraction.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(models)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Volumes/ssd/code/FaceID-model/test_various-face-extraction.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m   emb \u001b[39m=\u001b[39m DeepFace\u001b[39m.\u001b[39;49mrepresent(img_path\u001b[39m=\u001b[39;49mimg_path, model_name \u001b[39m=\u001b[39;49m models[i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/ssd/code/FaceID-model/test_various-face-extraction.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(emb))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/ssd/code/FaceID-model/test_various-face-extraction.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mif\u001b[39;00m num \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch-cpu/lib/python3.8/site-packages/deepface/DeepFace.py:754\u001b[0m, in \u001b[0;36mrepresent\u001b[0;34m(img_path, model_name, model, enforce_detection, detector_backend, align, normalization)\u001b[0m\n\u001b[1;32m    751\u001b[0m input_shape_x, input_shape_y \u001b[39m=\u001b[39m functions\u001b[39m.\u001b[39mfind_input_shape(model)\n\u001b[1;32m    753\u001b[0m \u001b[39m#detect and align\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m img \u001b[39m=\u001b[39m functions\u001b[39m.\u001b[39;49mpreprocess_face(img \u001b[39m=\u001b[39;49m img_path\n\u001b[1;32m    755\u001b[0m \t, target_size\u001b[39m=\u001b[39;49m(input_shape_y, input_shape_x)\n\u001b[1;32m    756\u001b[0m \t, enforce_detection \u001b[39m=\u001b[39;49m enforce_detection\n\u001b[1;32m    757\u001b[0m \t, detector_backend \u001b[39m=\u001b[39;49m detector_backend\n\u001b[1;32m    758\u001b[0m \t, align \u001b[39m=\u001b[39;49m align)\n\u001b[1;32m    760\u001b[0m \u001b[39m#---------------------------------\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[39m#custom normalization\u001b[39;00m\n\u001b[1;32m    763\u001b[0m img \u001b[39m=\u001b[39m functions\u001b[39m.\u001b[39mnormalize_input(img \u001b[39m=\u001b[39m img, normalization \u001b[39m=\u001b[39m normalization)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch-cpu/lib/python3.8/site-packages/deepface/commons/functions.py:178\u001b[0m, in \u001b[0;36mpreprocess_face\u001b[0;34m(img, target_size, grayscale, enforce_detection, detector_backend, return_region, align)\u001b[0m\n\u001b[1;32m    175\u001b[0m img \u001b[39m=\u001b[39m load_image(img)\n\u001b[1;32m    176\u001b[0m base_img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m--> 178\u001b[0m img, region \u001b[39m=\u001b[39m detect_face(img \u001b[39m=\u001b[39;49m img, detector_backend \u001b[39m=\u001b[39;49m detector_backend, grayscale \u001b[39m=\u001b[39;49m grayscale, enforce_detection \u001b[39m=\u001b[39;49m enforce_detection, align \u001b[39m=\u001b[39;49m align)\n\u001b[1;32m    180\u001b[0m \u001b[39m#--------------------------\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m img\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch-cpu/lib/python3.8/site-packages/deepface/commons/functions.py:110\u001b[0m, in \u001b[0;36mdetect_face\u001b[0;34m(img, detector_backend, grayscale, enforce_detection, align)\u001b[0m\n\u001b[1;32m    103\u001b[0m \t\u001b[39mreturn\u001b[39;00m img, img_region\n\u001b[1;32m    105\u001b[0m \u001b[39m#----------------------------------------------\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[39m#detector stored in a global variable in FaceDetector object.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m#this call should be completed very fast because it will return found in memory\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m#it will not build face detector model in each call (consider for loops)\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m face_detector \u001b[39m=\u001b[39m FaceDetector\u001b[39m.\u001b[39;49mbuild_model(detector_backend)\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m \tdetected_face, img_region \u001b[39m=\u001b[39m FaceDetector\u001b[39m.\u001b[39mdetect_face(face_detector, detector_backend, img, align)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch-cpu/lib/python3.8/site-packages/deepface/detectors/FaceDetector.py:27\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(detector_backend)\u001b[0m\n\u001b[1;32m     24\u001b[0m face_detector \u001b[39m=\u001b[39m backends\u001b[39m.\u001b[39mget(detector_backend)\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m face_detector:\n\u001b[0;32m---> 27\u001b[0m     face_detector \u001b[39m=\u001b[39m face_detector()\n\u001b[1;32m     28\u001b[0m     face_detector_obj[detector_backend] \u001b[39m=\u001b[39m face_detector\n\u001b[1;32m     29\u001b[0m     \u001b[39m#print(detector_backend,\" built\")\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch-cpu/lib/python3.8/site-packages/deepface/detectors/OpenCvWrapper.py:10\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_model\u001b[39m():\n\u001b[1;32m      8\u001b[0m \tdetector \u001b[39m=\u001b[39m{}\n\u001b[0;32m---> 10\u001b[0m \tdetector[\u001b[39m\"\u001b[39m\u001b[39mface_detector\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m build_cascade(\u001b[39m'\u001b[39;49m\u001b[39mhaarcascade\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m \tdetector[\u001b[39m\"\u001b[39m\u001b[39meye_detector\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m build_cascade(\u001b[39m'\u001b[39m\u001b[39mhaarcascade_eye\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \t\u001b[39mreturn\u001b[39;00m detector\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch-cpu/lib/python3.8/site-packages/deepface/detectors/OpenCvWrapper.py:23\u001b[0m, in \u001b[0;36mbuild_cascade\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m face_detector_path \u001b[39m=\u001b[39m opencv_path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhaarcascade_frontalface_default.xml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(face_detector_path) \u001b[39m!=\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m \t\u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mConfirm that opencv is installed on your environment! Expected path \u001b[39m\u001b[39m\"\u001b[39m,face_detector_path,\u001b[39m\"\u001b[39m\u001b[39m violated.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m face_detector \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCascadeClassifier(face_detector_path)\n\u001b[1;32m     27\u001b[0m \u001b[39mreturn\u001b[39;00m face_detector\n",
      "\u001b[0;31mValueError\u001b[0m: ('Confirm that opencv is installed on your environment! Expected path ', '/Users/KC/opt/anaconda3/envs/torch-cpu/lib/python3.8/site-packages/data/haarcascade_frontalface_default.xml', ' violated.')"
     ]
    }
   ],
   "source": [
    "# embedding data to be saved as numpy type\n",
    "''' embedding numpy matrix form\n",
    "      ---models--- label\n",
    "      +-----------+---+\n",
    "      |           | 0 |\n",
    "data  |           | 0 |\n",
    "      |           | 0 |\n",
    "      |           | 1 |\n",
    "      +-----------+---+\n",
    "'''\n",
    "\n",
    "\n",
    "models = cfg['models']\n",
    "\n",
    "\n",
    "data_source = './data/photos_from_video/'\n",
    "user_names = cfg['user_names']\n",
    "print(user_names)\n",
    "theNumberOfImages = cfg['theNumberOfImages']\n",
    "save_folder_for_embedding_numpy = cfg['save_path_for_embedding_numpy']\n",
    "\n",
    "\n",
    "emb_numpy_matrix = np.zeros(shape = (theNumerOfImages*(len(user_names)+1), len(models)+1))\n",
    "print(f'emb_numpy_martix shape: {emb_numpy_matrix.shape}')\n",
    "\n",
    "for model_num in range(len(models)):\n",
    "  temp_emb_numpy_matrix = np.zeros(shape = (theNumerOfImages, len(models)+1))\n",
    "  print(f'temp_emb_numpy_martix shape: {temp_emb_numpy_matrix.shape}')\n",
    "  \n",
    "  for label, user_name in enumerate(user_names):\n",
    "    temp_emb_numpy_matrix[:, len(models)+1] = label\n",
    "    \n",
    "    emb_list_col = []\n",
    "    for num in range(theNumberOfImages):\n",
    "      img_path = data_source + user_name + '/' + str(num) + '.jpg'\n",
    "      emb = DeepFace.represent(img_path=img_path, model_name = models[model_num])\n",
    "      if isinstance(emb, np.ndarray):\n",
    "        emb_list_col.append(emb)\n",
    "    \n",
    "    \n",
    "    start_row = label*theNumberOfImages\n",
    "    end_row = ((label+1) *  theNumberOfImages)-1\n",
    "    print(f'the data row number {start_row} ~ {end_row}')\n",
    "    emb_numpy_matrix[start_row:end_row, model_num] = np.array(emb_list_col)\n",
    "  \n",
    "  \n",
    "try: \n",
    "  save_path = save_folder_for_embedding_numpy + 'embedding_numpy_matrix.npy'\n",
    "  np.save(save_path_for_embedding_numpy, emb_numpy_matrix, allow_pickle=True)        \n",
    "except:\n",
    "  print(f\"failed saving numpy data in {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder_for_embedding_numpy = cfg['save_folder_for_embedding_numpy']\n",
    "load_path = save_folder_for_embedding_numpy + 'embedding_numpy_matrix.npy'\n",
    "emb_numpy_matrix = np.load(load_path)\n",
    "\n",
    "import pandas as pd\n",
    "from utils import pca\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = cfg['models']\n",
    "for model_num in range(len(model)):\n",
    "  labels = emb_numpy_matrix[:, len(model)+1]\n",
    "  emb_data = emb_numpy_matrix[:, model_num]\n",
    "  \n",
    "  print(f'label shape: {labels.shape} emb_data shape: {emb_data.shape}')\n",
    "  pca_x1, pca_x2 = execute_pca(emb_data)\n",
    "  \n",
    "  combined_array = np.column_stack([pca_x1, pca_x2, labels])\n",
    "  df_for_pca = pd.DataFrame(combined_array, columns = ['pca_x1', 'pca_x2', 'labels'])\n",
    "  \n",
    "  fig = plt.figure(1, figsize=(15, 10))\n",
    "  sns.scatterplot(data = df_for_pca, x = 'pca_x1', y = 'pca_x2', hue = 'labels')\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bc919d28741a19d05fc0e9f0958a353a64c6d71d6c217f4c6045e723d64b717"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
